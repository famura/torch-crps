{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Index","text":""},{"location":"#torch-crps","title":"torch-crps","text":"<p> <p>Implementations of the Continuously-Ranked Probability Score (CRPS) using PyTorch</p>"},{"location":"#background","title":"Background","text":"<p>The Continuously-Ranked Probability Score (CRPS) is a strictly proper scoring rule. It assesses how well a distribution with the cumulative distribution function \\(F\\) is explaining an observation \\(y\\)</p> \\[ \\text{CRPS}(F,y) = \\int _{\\mathbb {R} }(F(x)-\\mathbb {1} (x\\geq y))^{2}dx \\qquad (\\text{integral formulation}) \\] <p>where \\(1\\) denoted the indicator function.</p> <p>In Section 2 of this paper Zamo &amp; Naveau list 3 different formulations of the CRPS.</p>"},{"location":"#incomplete-list-of-sources-that-i-came-across-while-researching-about-the-crps","title":"Incomplete list of sources that I came across while researching about the CRPS","text":"<ul> <li>Hersbach, \"Decomposition of the Continuous Ranked Probability Score for Ensemble Prediction Systems\"; 2000</li> <li>Gneiting et al.; \"Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistis and Minimum CRPS Estimation\"; 2004</li> <li>Gneiting &amp; Raftery; \"Strictly Proper Scoring Rules, Prediction, and Estimation\"; 2007</li> <li>Zamo &amp; Naveau; \"Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts\"; 2018</li> <li>Jordan et al.; \"Evaluating Probabilistic Forecasts with scoringRules\"; 2019</li> <li>Olivares &amp; N\u00e9giar &amp; Ma et al; \"CLOVER: Probabilistic Forecasting with Coherent Learning Objective Reparameterization\"; 2023</li> <li>Vermorel &amp; Tikhonov; \"Continuously-Ranked Probability Score (CRPS)\" blog post; 2024</li> <li>Nvidia; \"PhysicsNeMo Framework\" source code; 2025</li> <li>Zheng &amp; Sun; \"MVG-CRPS: A Robust Loss Function for Multivariate Probabilistic Forecasting\"; 2025</li> </ul>"},{"location":"#application-to-machine-learning","title":"Application to Machine Learning","text":"<p>The CRPS can be used as a loss function in machine learning, just like the well-known negative log-likelihood loss which is the log scoring rule.</p> <p>The parametrized model outputs a distribution \\(q(x)\\). The CRPS loss evaluates how good \\(q(x)\\) is explaining the observation \\(y\\). This is a distribution-to-point evaluation, which fits well for machine learning as the ground truth \\(y\\) almost always comes as fixed values.</p> <p>For processes over time and/or space, we need to estimate the CRPS for every point in time/space separately.</p> <p>There is work on multi-variate CRPS estimation, but it is not part of this repo.</p>"},{"location":"#implementation","title":"Implementation","text":"<p>The integral formulation is infeasible to naively evaluate on a computer due to the infinite integration over \\(x\\).</p> <p>I found Nvidia's implementation of the CRPS for ensemble preductions in \\(M log(M)\\) time inspiring to read.</p> <p> Please have a look at the documentation to get started.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":"<p>Compare with latest</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#using-pip","title":"Using <code>pip</code>","text":"<p>You can <code>pip install</code> different versions of this project as usual:</p> <pre><code>pip install torch-crps\n</code></pre>"},{"location":"installation/#any-version-from-github","title":"Any Version from GitHub","text":"<p>You can install any version directly from GitHub:</p> <pre><code>GIT_REF=main # or some other ref, e.g. a branch or tag\npip install git+https://github.com/famura/torch-crps@${GIT_REF}\n</code></pre>"},{"location":"licenses/","title":"Licenses","text":""},{"location":"licenses/#this-project","title":"This Project","text":"<pre><code>    &lt;a href=\"https://github.com/famura/torch-crps\"&gt;torch-crps&lt;/a&gt; \u00a9 2025 by\n    &lt;a href=\"https://github.com/famura\"&gt;Fabio Muratore&lt;/a&gt; is licensed under\n    &lt;a href=\"https://creativecommons.org/licenses/by/4.0/\"&gt;CC BY 4.0&lt;/a&gt;\n</code></pre>"},{"location":"licenses/#third-party-libraries","title":"Third-Party Libraries","text":""},{"location":"licenses/#license-summary","title":"License Summary","text":"Count License 1 Academic Free License (AFL); MIT License 1 Apache 4 Apache Software License 3 Apache Software License; BSD License 3 Apache-2.0 20 BSD License 1 BSD-2-Clause 8 BSD-3-Clause 1 BSD-3-Clause AND 0BSD AND MIT AND Zlib AND CC0-1.0 5 ISC 1 ISC License (ISCL) 23 MIT 15 MIT License 1 MIT-CMU 2 MPL-2.0 2 Mozilla Public License 2.0 (MPL 2.0) 1 NVIDIA Proprietary Software 14 Other/Proprietary License 1 PSF-2.0 3 Python Software Foundation License 1 Unlicense"},{"location":"licenses/#details","title":"Details","text":"Name Version License Author URL Description GitPython 3.1.45 BSD-3-Clause Sebastian Thiel, Michael Trier https://github.com/gitpython-developers/GitPython GitPython is a Python library used to interact with Git repositories Jinja2 3.1.6 BSD License UNKNOWN https://github.com/pallets/jinja/ A very fast and expressive template engine. Markdown 3.10 BSD-3-Clause Manfred Stienstra, Yuri Takhteyev https://Python-Markdown.github.io/ Python implementation of John Gruber's Markdown. MarkupSafe 3.0.3 BSD-3-Clause UNKNOWN https://github.com/pallets/markupsafe/ Safely add untrusted strings to HTML/XML markup. PyYAML 6.0.3 MIT License Kirill Simonov https://pyyaml.org/ YAML parser and emitter for Python Pygments 2.19.2 BSD License Georg Brandl georg@python.org https://pygments.org Pygments is a syntax highlighting package written in Python. babel 2.17.0 BSD License Armin Ronacher https://babel.pocoo.org/ Internationalization utilities backrefs 6.1 MIT Isaac Muse Isaac.Muse@gmail.com https://github.com/facelessuser/backrefs A wrapper around re and regex that adds additional back references. certifi 2025.11.12 Mozilla Public License 2.0 (MPL 2.0) Kenneth Reitz https://github.com/certifi/python-certifi Python package for providing Mozilla's CA Bundle. cfgv 3.5.0 MIT Anthony Sottile https://github.com/asottile/cfgv Validate configuration and produce human readable error messages. charset-normalizer 3.4.4 MIT \"Ahmed R. TAHRI\" tahri.ahmed@proton.me https://github.com/jawah/charset_normalizer/blob/master/CHANGELOG.md The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. click 8.3.1 BSD-3-Clause UNKNOWN https://github.com/pallets/click/ Composable command line interface toolkit colorama 0.4.6 BSD License Jonathan Hartley tartley@tartley.com https://github.com/tartley/colorama Cross-platform colored terminal text. contourpy 1.3.3 BSD License Ian Thomas ianthomas23@gmail.com https://github.com/contourpy/contourpy Python library for calculating contours of 2D quadrilateral grids coverage 7.13.0 Apache-2.0 Ned Batchelder and 246 others https://github.com/coveragepy/coveragepy Code coverage measurement for Python csscompressor 0.9.5 BSD License Yury Selivanov http://github.com/sprymix/csscompressor A python port of YUI CSS Compressor cycler 0.12.1 BSD License Thomas A Caswell matplotlib-users@python.org https://matplotlib.org/cycler/ Composable style cycles defusedxml 0.7.1 Python Software Foundation License Christian Heimes https://github.com/tiran/defusedxml XML bomb protection for Python stdlib modules distlib 0.4.0 Python Software Foundation License Vinay Sajip https://github.com/pypa/distlib Distribution utilities execnet 2.1.2 MIT holger krekel and others https://execnet.readthedocs.io/en/latest/ execnet: rapid multi-Python deployment filelock 3.20.1 Unlicense UNKNOWN https://github.com/tox-dev/py-filelock A platform independent file lock. fonttools 4.61.1 MIT Just van Rossum http://github.com/fonttools/fonttools Tools to manipulate font files fsspec 2025.12.0 BSD-3-Clause UNKNOWN https://github.com/fsspec/filesystem_spec File-system specification genbadge 1.1.3 BSD License Sylvain MARIE sylvain.marie@se.com https://github.com/smarie/python-genbadge Generate badges for tools that do not provide one. ghp-import 2.1.0 Apache Software License Paul Joseph Davis https://github.com/c-w/ghp-import Copy your docs directly to the gh-pages branch. git-changelog 2.7.0 ISC =?utf-8?q?Timoth=C3=A9e_Mazzucotelli?= dev@pawamoy.fr https://pawamoy.github.io/git-changelog Automatic Changelog generator using Jinja2 templates. gitdb 4.0.12 BSD License Sebastian Thiel https://github.com/gitpython-developers/gitdb Git Object Database griffe 1.15.0 ISC =?utf-8?q?Timoth=C3=A9e_Mazzucotelli?= dev@pawamoy.fr https://mkdocstrings.github.io/griffe Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. hjson 3.1.0 Academic Free License (AFL); MIT License Christian Zangl http://github.com/hjson/hjson-py Hjson, a user interface for JSON. htmlmin2 0.1.13 BSD License Dave Mankoff https://htmlmin.readthedocs.io/en/latest/ An HTML Minifier identify 2.6.15 MIT Chris Kuehl https://github.com/pre-commit/identify File identification library for Python idna 3.11 BSD-3-Clause Kim Davies kim+pypi@gumleaf.org https://github.com/kjd/idna Internationalized Domain Names in Applications (IDNA) importlib_metadata 8.7.1 Apache-2.0 \"Jason R. Coombs\" jaraco@jaraco.com https://github.com/python/importlib_metadata Read metadata from Python packages importlib_resources 6.5.2 Apache Software License Barry Warsaw barry@python.org https://github.com/python/importlib_resources Read resources from Python packages iniconfig 2.3.0 MIT Ronny Pfannschmidt opensource@ronnypfannschmidt.de, Holger Krekel holger.krekel@gmail.com https://github.com/pytest-dev/iniconfig brain-dead simple config-ini parsing jsmin 3.0.1 MIT License Dave St.Germain https://github.com/tikitu/jsmin/ JavaScript minifier. kiwisolver 1.4.9 BSD License The Nucleic Development Team sccolbert@gmail.com https://github.com/nucleic/kiwi A fast implementation of the Cassowary constraint solver markdown-it-py 4.0.0 MIT License Chris Sewell chrisj_sewell@hotmail.com https://github.com/executablebooks/markdown-it-py Python port of markdown-it. Markdown parsing, done right! matplotlib 3.10.8 Python Software Foundation License John D. Hunter, Michael Droettboom https://matplotlib.org Python plotting package mdurl 0.1.2 MIT License Taneli Hukkinen hukkin@users.noreply.github.com https://github.com/executablebooks/mdurl Markdown URL utilities mergedeep 1.3.4 MIT License Travis Clarke https://github.com/clarketm/mergedeep A deep merge function for \ud83d\udc0d. mike 2.1.3 BSD License Jim Porter https://github.com/jimporter/mike Manage multiple versions of your MkDocs-powered documentation mkdocs 1.6.1 BSD-2-Clause Tom Christie tom@tomchristie.com https://github.com/mkdocs/mkdocs Project documentation with Markdown. mkdocs-autorefs 1.4.3 ISC Oleh Prypin oleh@pryp.in, =?utf-8?q?Timoth=C3=A9e_Mazzucotelli?= dev@pawamoy.fr https://mkdocstrings.github.io/autorefs Automatically link across pages in MkDocs. mkdocs-get-deps 0.2.0 MIT Oleh Prypin oleh@pryp.in https://github.com/mkdocs/get-deps MkDocs extension that lists all dependencies according to a mkdocs.yml file mkdocs-git-revision-date-localized-plugin 1.5.0 MIT License Tim Vink vinktim@gmail.com https://github.com/timvink/mkdocs-git-revision-date-localized-plugin Mkdocs plugin that enables displaying the localized date of the last git modification of a markdown file. mkdocs-macros-plugin 1.5.0 MIT License Laurent Franceschetti https://github.com/fralau/mkdocs_macros_plugin Unleash the power of MkDocs with macros and variables mkdocs-material 9.7.1 MIT Martin Donath martin.donath@squidfunk.com https://github.com/squidfunk/mkdocs-material Documentation that simply works mkdocs-material-extensions 1.3.1 MIT Isaac Muse Isaac.Muse@gmail.com https://github.com/facelessuser/mkdocs-material-extensions Extension pack for Python Markdown and MkDocs Material. mkdocs-minify-plugin 0.8.0 MIT License Byrne Reese, Lars Wilhelmer https://github.com/byrnereese/mkdocs-minify-plugin An MkDocs plugin to minify HTML, JS or CSS files prior to being written to disk mkdocs-typer 0.0.3 Apache Bruce Szalwinski https://github.com/bruce-szalwinski/mkdocs-typer An MkDocs extension to generate documentation for Typer command line applications mkdocstrings 1.0.0 ISC =?utf-8?q?Timoth=C3=A9e_Mazzucotelli?= dev@pawamoy.fr https://mkdocstrings.github.io Automatic documentation from sources, for MkDocs. mkdocstrings-python 2.0.1 ISC =?utf-8?q?Timoth=C3=A9e_Mazzucotelli?= dev@pawamoy.fr https://mkdocstrings.github.io/python A Python handler for mkdocstrings. mpmath 1.3.0 BSD License Fredrik Johansson http://mpmath.org/ Python library for arbitrary-precision floating-point arithmetic networkx 3.6.1 BSD-3-Clause Aric Hagberg hagberg@lanl.gov https://networkx.org/ Python package for creating and manipulating graphs and networks nodeenv 1.10.0 BSD License Eugene Kalinin https://github.com/ekalinin/nodeenv Node.js virtual environment builder numpy 2.4.0 BSD-3-Clause AND 0BSD AND MIT AND Zlib AND CC0-1.0 Travis E. Oliphant et al. https://numpy.org Fundamental package for array computing in Python nvidia-cublas-cu12 12.8.4.1 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUBLAS native runtime libraries nvidia-cuda-cupti-cu12 12.8.90 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUDA profiling tools runtime libs. nvidia-cuda-nvrtc-cu12 12.8.93 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone NVRTC native runtime libraries nvidia-cuda-runtime-cu12 12.8.90 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUDA Runtime native Libraries nvidia-cudnn-cu12 9.10.2.21 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone cuDNN runtime libraries nvidia-cufft-cu12 11.3.3.83 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUFFT native runtime libraries nvidia-cufile-cu12 1.13.1.3 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone cuFile GPUDirect libraries nvidia-curand-cu12 10.3.9.90 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CURAND native runtime libraries nvidia-cusolver-cu12 11.7.3.90 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUDA solver native runtime libraries nvidia-cusparse-cu12 12.5.8.93 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone CUSPARSE native runtime libraries nvidia-cusparselt-cu12 0.7.1 NVIDIA Proprietary Software NVIDIA Corporation https://developer.nvidia.com/cusparselt NVIDIA cuSPARSELt nvidia-nccl-cu12 2.27.5 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone NVIDIA Collective Communication Library (NCCL) Runtime nvidia-nvjitlink-cu12 12.8.93 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone Nvidia JIT LTO Library nvidia-nvshmem-cu12 3.3.20 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone NVSHMEM creates a global address space that provides efficient and scalable communication for NVIDIA GPU clusters. nvidia-nvtx-cu12 12.8.90 Other/Proprietary License Nvidia CUDA Installer Team https://developer.nvidia.com/cuda-zone NVIDIA Tools Extension packaging 25.0 Apache Software License; BSD License Donald Stufft donald@stufft.io https://github.com/pypa/packaging Core utilities for Python packages paginate 0.5.7 MIT License Christoph Haas https://github.com/Signum/paginate Divides large result sets into pages for easier browsing pandas 2.3.3 BSD License The Pandas Development Team pandas-dev@python.org https://pandas.pydata.org Powerful data structures for data analysis, time series, and statistics pathspec 0.12.1 Mozilla Public License 2.0 (MPL 2.0) \"Caleb P. Burns\" cpburnz@gmail.com UNKNOWN Utility library for gitignore style pattern matching of file paths. pillow 12.0.0 MIT-CMU \"Jeffrey A. Clark\" aclark@aclark.net https://python-pillow.github.io Python Imaging Library (fork) platformdirs 4.5.1 MIT UNKNOWN https://github.com/tox-dev/platformdirs A small Python package for determining appropriate platform-specific dirs, e.g. a <code>user data dir</code>. pluggy 1.6.0 MIT License Holger Krekel holger@merlinux.eu UNKNOWN plugin and hook calling mechanisms for python pre_commit 4.5.1 MIT Anthony Sottile https://github.com/pre-commit/pre-commit A framework for managing and maintaining multi-language pre-commit hooks. pymdown-extensions 10.19.1 MIT Isaac Muse Isaac.Muse@gmail.com https://github.com/facelessuser/pymdown-extensions Extension pack for Python Markdown. pyparsing 3.3.1 MIT Paul McGuire ptmcg.gm+pyparsing@gmail.com https://github.com/pyparsing/pyparsing/ pyparsing - Classes and methods to define and execute parsing grammars pytest 9.0.2 MIT Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin, Others (See AUTHORS) https://docs.pytest.org/en/latest/ pytest: simple powerful testing with Python pytest-cov 7.0.0 MIT Marc Schlaich marc.schlaich@gmail.com https://pytest-cov.readthedocs.io/en/latest/changelog.html Pytest plugin for measuring coverage. pytest-html 4.1.1 MPL-2.0 Dave Hunt dhunt@mozilla.com, Jim Brannlund jimbrannlund@fastmail.com https://github.com/pytest-dev/pytest-html pytest plugin for generating HTML reports pytest-metadata 3.1.1 MPL-2.0 Dave Hunt dhunt@mozilla.com, Jim Brannlund jimbrannlund@fastmail.com https://github.com/pytest-dev/pytest-metadata pytest plugin for test session metadata pytest-xdist 3.8.0 MIT holger krekel and contributors pytest-dev@python.org, holger@merlinux.eu https://github.com/pytest-dev/pytest-xdist pytest xdist plugin for distributed testing, most importantly across multiple CPUs python-dateutil 2.9.0.post0 Apache Software License; BSD License Gustavo Niemeyer https://github.com/dateutil/dateutil Extensions to the standard Python datetime module pytz 2025.2 MIT License Stuart Bishop http://pythonhosted.org/pytz World timezone definitions, modern and historical pyyaml_env_tag 1.1 MIT Waylan Limberg waylan.limberg@icloud.com https://github.com/waylan/pyyaml-env-tag A custom YAML tag for referencing environment variables in YAML files. requests 2.32.5 Apache Software License Kenneth Reitz https://requests.readthedocs.io Python HTTP for Humans. rich 14.2.0 MIT License Will McGugan https://github.com/Textualize/rich Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal scipy 1.16.3 BSD License UNKNOWN https://scipy.org/ Fundamental algorithms for scientific computing in Python seaborn 0.13.2 BSD License Michael Waskom mwaskom@gmail.com https://github.com/mwaskom/seaborn Statistical data visualization semver 3.0.4 BSD License Kostiantyn Rybnikov k-bx@k-bx.com, Tom Schraitle toms@suse.de https://python-semver.readthedocs.io/en/latest/changelog.html Python helper for Semantic Versioning (https://semver.org) shellingham 1.5.4 ISC License (ISCL) Tzu-ping Chung https://github.com/sarugaku/shellingham Tool to Detect Surrounding Shell six 1.17.0 MIT License Benjamin Peterson https://github.com/benjaminp/six Python 2 and 3 compatibility utilities smmap 5.0.2 BSD License Sebastian Thiel https://github.com/gitpython-developers/smmap A pure Python implementation of a sliding window memory map manager super_collections 0.6.2 MIT License Laurent Franceschetti https://github.com/fralau/super-collections file: README.md sympy 1.14.0 BSD License SymPy development team https://sympy.org Computer algebra system (CAS) in Python termcolor 3.2.0 MIT Konstantin Lepa konstantin.lepa@gmail.com https://github.com/termcolor/termcolor ANSI color formatting for output in terminal torch 2.9.1 BSD-3-Clause PyTorch Team packages@pytorch.org https://pytorch.org Tensors and Dynamic neural networks in Python with strong GPU acceleration triton 3.5.1 MIT License Philippe Tillet https://github.com/triton-lang/triton/ A language and compiler for custom Deep Learning operations typer 0.21.0 MIT =?utf-8?q?Sebasti=C3=A1n_Ram=C3=ADrez?= tiangolo@gmail.com https://github.com/fastapi/typer Typer, build great CLIs. Easy to code. Based on Python type hints. typing_extensions 4.15.0 PSF-2.0 \"Guido van Rossum, Jukka Lehtosalo, \u0141ukasz Langa, Michael Lee\" levkivskyi@gmail.com https://github.com/python/typing_extensions Backported and Experimental Type Hints for Python 3.9+ tzdata 2025.3 Apache-2.0 Python Software Foundation https://github.com/python/tzdata Provider of IANA time zone data urllib3 2.6.2 MIT Andrey Petrov andrey.petrov@shazow.net https://github.com/urllib3/urllib3/blob/main/CHANGES.rst HTTP library with thread-safe connection pooling, file post, and more. verspec 0.1.0 Apache Software License; BSD License Jim Porter https://github.com/jimporter/verspec Flexible version handling virtualenv 20.35.4 MIT UNKNOWN https://github.com/pypa/virtualenv Virtual Python Environment builder watchdog 6.0.0 Apache Software License Micka\u00ebl Schoentgen https://github.com/gorakhargosh/watchdog Filesystem events monitoring zipp 3.23.0 MIT \"Jason R. Coombs\" jaraco@jaraco.com https://github.com/jaraco/zipp Backport of pathlib-compatible object wrapper for zip files"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#torch_crps.analytical_crps","title":"<code>torch_crps.analytical_crps</code>","text":""},{"location":"reference/#torch_crps.analytical_crps.crps_analytical_naive_integral","title":"<code>crps_analytical_naive_integral(q, y, x_min=-100.0, x_max=100.0, x_steps=5001)</code>","text":"<p>Compute the Continuous Ranked Probability Score (CRPS) using the naive integral method.</p> <p>Note</p> <p>This function is not differentiable with respect to <code>y</code> due to the indicator function.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>Distribution</code> <p>A PyTorch distribution object, typically a model's output distribution.</p> required <code>y</code> <code>Tensor</code> <p>Observed values, of shape (num_samples,).</p> required <code>x_min</code> <code>float</code> <p>Lower limit for integration for the probability space.</p> <code>-100.0</code> <code>x_max</code> <code>float</code> <p>Upper limit for integration for the probability space.</p> <code>100.0</code> <code>x_steps</code> <code>int</code> <p>Number of steps for numerical integration.</p> <code>5001</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>CRPS values for each observation, of shape (num_samples,).</p> Source code in <code>torch_crps/analytical_crps.py</code> <pre><code>def crps_analytical_naive_integral(\n    q: Distribution,\n    y: torch.Tensor,\n    x_min: float = -1e2,\n    x_max: float = 1e2,\n    x_steps: int = 5001,\n) -&gt; torch.Tensor:\n    \"\"\"Compute the Continuous Ranked Probability Score (CRPS) using the naive integral method.\n\n    Note:\n        This function is not differentiable with respect to `y` due to the indicator function.\n\n    Args:\n        q: A PyTorch distribution object, typically a model's output distribution.\n        y: Observed values, of shape (num_samples,).\n        x_min: Lower limit for integration for the probability space.\n        x_max: Upper limit for integration for the probability space.\n        x_steps: Number of steps for numerical integration.\n\n    Returns:\n        CRPS values for each observation, of shape (num_samples,).\n    \"\"\"\n\n    def integrand(x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Compute the integrand $F(x) - 1(y &lt;= x))^2$ to be used by the torch integration functions.\"\"\"\n        if not isinstance(q, StudentT):\n            # Default case.\n            cdf_value = q.cdf(x)\n        else:\n            # Special case for torch's StudentT distributions which do not have a cdf method implemented.\n            z = (x - q.loc) / q.scale\n            cdf_value = _standardized_studentt_cdf_via_scipy(z, q.df)\n        indicator = (y_expanded &lt;= x).float()\n        return (cdf_value - indicator) ** 2\n\n    # Set integration limits.\n    x_values = torch.linspace(\n        start=torch.tensor(x_min, dtype=y.dtype, device=y.device),\n        end=torch.tensor(x_max, dtype=y.dtype, device=y.device),\n        steps=x_steps,\n        dtype=y.dtype,\n        device=y.device,\n    )\n\n    # Reshape for proper broadcasting.\n    x_values = x_values.unsqueeze(-1)  # shape: (x_steps, 1)\n    y_expanded = y.unsqueeze(0)  # shape: (1, num_samples)\n\n    # Compute the integral using the trapezoidal rule.\n    integral_values = integrand(x_values)\n    crps_values = torch.trapezoid(integral_values, x_values.squeeze(-1), dim=0)\n\n    return crps_values\n</code></pre>"},{"location":"reference/#torch_crps.analytical_crps.crps_analytical_normal","title":"<code>crps_analytical_normal(q, y)</code>","text":"<p>Compute the analytical CRPS assuming a normal distribution.</p> <p>See Also</p> <p>Gneiting &amp; Raftery; \"Strictly Proper Scoring Rules, Prediction, and Estimation\"; 2007 Equation (5) for the analytical formula for CRPS of Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>Normal</code> <p>A PyTorch Normal distribution object, typically a model's output distribution.</p> required <code>y</code> <code>Tensor</code> <p>Observed values, of shape (num_samples,).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>CRPS values for each observation, of shape (num_samples,).</p> Source code in <code>torch_crps/analytical_crps.py</code> <pre><code>def crps_analytical_normal(\n    q: Normal,\n    y: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Compute the analytical CRPS assuming a normal distribution.\n\n    See Also:\n        Gneiting &amp; Raftery; \"Strictly Proper Scoring Rules, Prediction, and Estimation\"; 2007\n        Equation (5) for the analytical formula for CRPS of Normal distribution.\n\n    Args:\n        q: A PyTorch Normal distribution object, typically a model's output distribution.\n        y: Observed values, of shape (num_samples,).\n\n    Returns:\n        CRPS values for each observation, of shape (num_samples,).\n    \"\"\"\n    # Compute standard normal CDF and PDF.\n    z = (y - q.loc) / q.scale  # standardize\n    standard_normal = torch.distributions.Normal(0, 1)\n    phi_z = standard_normal.cdf(z)  # \u03a6(z)\n    pdf_z = torch.exp(standard_normal.log_prob(z))  # \u03c6(z)\n\n    # Analytical CRPS formula.\n    crps = q.scale * (z * (2 * phi_z - 1) + 2 * pdf_z - 1 / torch.sqrt(torch.tensor(torch.pi)))\n\n    return crps\n</code></pre>"},{"location":"reference/#torch_crps.analytical_crps.crps_analytical_studentt","title":"<code>crps_analytical_studentt(q, y)</code>","text":"<p>Compute the analytical CRPS assuming a StudentT distribution.</p> <p>This implements the closed-form formula from Jordan et al. (2019), see Appendix A.2.</p> <p>For the standardized StudentT distribution:</p> \\[ \\text{CRPS}(F_\\nu, z) = z(2F_\\nu(z) - 1) + 2f_\\nu(z)\\frac{\\nu + z^2}{\\nu - 1} - \\frac{2\\sqrt{\\nu}}{\\nu - 1} \\frac{B(\\frac{1}{2}, \\nu - \\frac{1}{2})}{B(\\frac{1}{2}, \\frac{\\nu}{2})^2} \\] <p>where \\(z\\) is the standardized value, \\(F_\\nu\\) is the CDF, \\(f_\\nu\\) is the PDF of the standard StudentT distribution, \\(\\nu\\) is the degrees of freedom, and \\(B\\) is the beta function.</p> <p>For the location-scale transformed distribution:</p> \\[ \\text{CRPS}(F_{\\nu,\\mu,\\sigma}, y) = \\sigma \\cdot \\text{CRPS}\\left(F_\\nu, \\frac{y-\\mu}{\\sigma}\\right) \\] <p>where \\(\\mu\\) is the location parameter, \\(\\sigma\\) is the scale parameter, and \\(y\\) is the observation.</p> <p>Note</p> <p>This formula is only valid for degrees of freedom \\(\\nu &gt; 1\\).</p> <p>See Also</p> <p>Jordan et al.; \"Evaluating Probabilistic Forecasts with scoringRules\"; 2019; Appendix A.2.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>StudentT</code> <p>A PyTorch StudentT distribution object, typically a model's output distribution.</p> required <code>y</code> <code>Tensor</code> <p>Observed values, of shape (num_samples,).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>CRPS values for each observation, of shape (num_samples,).</p> Source code in <code>torch_crps/analytical_crps.py</code> <pre><code>def crps_analytical_studentt(\n    q: StudentT,\n    y: torch.Tensor,\n) -&gt; torch.Tensor:\n    r\"\"\"Compute the analytical CRPS assuming a StudentT distribution.\n\n    This implements the closed-form formula from Jordan et al. (2019), see Appendix A.2.\n\n    For the standardized StudentT distribution:\n\n    $$ \\text{CRPS}(F_\\nu, z) = z(2F_\\nu(z) - 1) + 2f_\\nu(z)\\frac{\\nu + z^2}{\\nu - 1}\n    - \\frac{2\\sqrt{\\nu}}{\\nu - 1} \\frac{B(\\frac{1}{2}, \\nu - \\frac{1}{2})}{B(\\frac{1}{2}, \\frac{\\nu}{2})^2} $$\n\n    where $z$ is the standardized value, $F_\\nu$ is the CDF, $f_\\nu$ is the PDF of the standard StudentT\n    distribution, $\\nu$ is the degrees of freedom, and $B$ is the beta function.\n\n    For the location-scale transformed distribution:\n\n    $$ \\text{CRPS}(F_{\\nu,\\mu,\\sigma}, y) = \\sigma \\cdot \\text{CRPS}\\left(F_\\nu, \\frac{y-\\mu}{\\sigma}\\right) $$\n\n    where $\\mu$ is the location parameter, $\\sigma$ is the scale parameter, and $y$ is the observation.\n\n    Note:\n        This formula is only valid for degrees of freedom $\\nu &gt; 1$.\n\n    See Also:\n        Jordan et al.; \"Evaluating Probabilistic Forecasts with scoringRules\"; 2019; Appendix A.2.\n\n    Args:\n        q: A PyTorch StudentT distribution object, typically a model's output distribution.\n        y: Observed values, of shape (num_samples,).\n\n    Returns:\n        CRPS values for each observation, of shape (num_samples,).\n    \"\"\"\n    # Extract degrees of freedom (nu), location (mu), and scale (sigma).\n    df, loc, scale = q.df, q.loc, q.scale\n\n    if torch.any(df &lt;= 1):\n        raise ValueError(\"StudentT CRPS requires degrees of freedom &gt; 1\")\n\n    # Standardize, and create standard StudentT distribution for CDF and PDF.\n    z = (y - loc) / scale\n    standard_t = torch.distributions.StudentT(df, loc=0, scale=1)\n\n    # Compute standardized CDF F_nu(z) and PDF f_nu(z).\n    f_cdf_z = _standardized_studentt_cdf_via_scipy(z, df)\n    f_z = torch.exp(standard_t.log_prob(z))\n\n    # Compute the beta function ratio: B(1/2, nu - 1/2) / B(1/2, nu/2)^2\n    # Using the relationship: B(a,b) = Gamma(a) * Gamma(b) / Gamma(a+b)\n    # B(1/2, nu - 1/2) / B(1/2, nu/2)^2 = ( Gamma(1/2) * Gamma(nu-1/2) / Gamma(nu) ) /\n    #                                     ( Gamma(1/2) * Gamma(nu/2) / Gamma(nu/2 + 1/2) )^2\n    # Simplifying to Gamma(nu - 1/2) Gamma(nu/2 + 1/2)^2 / ( Gamma(nu)Gamma(nu/2)^2 )\n    # For numerical stability, we compute in log space.\n    log_gamma_half = torch.lgamma(torch.tensor(0.5, dtype=df.dtype, device=df.device))\n    log_gamma_df_minus_half = torch.lgamma(df - 0.5)\n    log_gamma_df_half = torch.lgamma(df / 2)\n    log_gamma_df_half_plus_half = torch.lgamma(df / 2 + 0.5)\n\n    # log[B(1/2, nu-1/2)] = log Gamma(1/2) + log Gamma(nu-1/2) - log Gamma(nu)\n    # log[B(1/2, nu/2)] = log Gamma(1/2) + log Gamma(nu/2) - log Gamma(nu/2 + 1/2)\n    # log[B(1/2, nu-1/2) / B(1/2, nu/2)^2] = log B(1/2, nu-1/2) - 2*log B(1/2, nu/2)\n    log_beta_ratio = (\n        log_gamma_half\n        + log_gamma_df_minus_half\n        - torch.lgamma(df)\n        - 2 * (log_gamma_half + log_gamma_df_half - log_gamma_df_half_plus_half)\n    )\n    beta_frac = torch.exp(log_beta_ratio)\n\n    # Compute the CRPS for standardized values.\n    crps_standard = (\n        z * (2 * f_cdf_z - 1) + 2 * f_z * (df + z**2) / (df - 1) - (2 * torch.sqrt(df) / (df - 1)) * beta_frac\n    )\n\n    # Apply location-scale transformation CRPS(F_{nu,mu,sigma}, y) = sigma * CRPS(F_nu, z) with z = (y - mu) / sigma.\n    crps = scale * crps_standard\n\n    return crps\n</code></pre>"},{"location":"reference/#torch_crps.ensemble_crps","title":"<code>torch_crps.ensemble_crps</code>","text":""},{"location":"reference/#torch_crps.ensemble_crps.crps_ensemble","title":"<code>crps_ensemble(x, y, biased=True)</code>","text":"<p>Computes the Continuous Ranked Probability Score (CRPS) for an ensemble forecast.</p> <p>This implementation uses the equalities</p> \\[ CRPS(F, y) = E[|X - y|] - 0.5 E[|X - X'|] \\] <p>and</p> \\[ CRPS(F, y) = E[|X - y|] + E[X] - 2 E[X F(X)] \\] <p>It is designed to be fully vectorized and handle any number of leading batch dimensions in the input tensors, as long as they are equal for <code>x</code> and <code>y</code>.</p> <p>See Also</p> <p>Zamo &amp; Naveau; \"Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts\"; 2017</p> <p>Note</p> <ul> <li>This implementation uses an efficient algorithm to compute the term E[|X - X'|] in O(m log(m)) time, where m is the number of ensemble members. This is achieved by sorting the ensemble predictions and using a mathematical identity to compute the mean absolute difference. You can also see this trick [here][https://docs.nvidia.com/physicsnemo/25.11/_modules/physicsnemo/metrics/general/crps.html]</li> <li>This implementation exactly matches the energy formula, see (NRG) and (eNRG), in Zamo &amp; Naveau (2017) while using the compuational trick which can be read from (ePWM) in the same paper. The factors &amp;\\beta_0$ and \\(\\beta_1\\) in (ePWM) together equal the second term, i.e., the half mean spread, here. In (ePWM) they pulled the mean out. The energy formula and the probability weighted moment formula are equivalent.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The ensemble predictions, of shape (*batch_shape, dim_ensemble).</p> required <code>y</code> <code>Tensor</code> <p>The ground truth observations, of shape (*batch_shape).</p> required <code>biased</code> <code>bool</code> <p>If True, uses the biased estimator for E[|X - X'|]. If False, uses the unbiased estimator. The unbiased estimator divides by m * (m - 1) instead of m\u00b2.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The calculated CRPS value for each forecast in the batch, of shape (*batch_shape).</p> Source code in <code>torch_crps/ensemble_crps.py</code> <pre><code>def crps_ensemble(x: torch.Tensor, y: torch.Tensor, biased: bool = True) -&gt; torch.Tensor:\n    r\"\"\"Computes the Continuous Ranked Probability Score (CRPS) for an ensemble forecast.\n\n    This implementation uses the equalities\n\n    $$ CRPS(F, y) = E[|X - y|] - 0.5 E[|X - X'|] $$\n\n    and\n\n    $$ CRPS(F, y) = E[|X - y|] + E[X] - 2 E[X F(X)] $$\n\n    It is designed to be fully vectorized and handle any number of leading batch dimensions in the input tensors,\n    as long as they are equal for `x` and `y`.\n\n    See Also:\n        Zamo &amp; Naveau; \"Estimation of the Continuous Ranked Probability Score with Limited Information and Applications\n        to Ensemble Weather Forecasts\"; 2017\n\n    Note:\n        - This implementation uses an efficient algorithm to compute the term E[|X - X'|] in O(m log(m)) time, where m\n        is the number of ensemble members. This is achieved by sorting the ensemble predictions and using a mathematical\n        identity to compute the mean absolute difference. You can also see this trick\n        [here][https://docs.nvidia.com/physicsnemo/25.11/_modules/physicsnemo/metrics/general/crps.html]\n        - This implementation exactly matches the energy formula, see (NRG) and (eNRG), in Zamo &amp; Naveau (2017) while\n        using the compuational trick which can be read from (ePWM) in the same paper. The factors &amp;\\beta_0$ and\n        $\\beta_1$ in (ePWM) together equal the second term, i.e., the half mean spread, here. In (ePWM) they pulled\n        the mean out. The energy formula and the probability weighted moment formula are equivalent.\n\n    Args:\n        x: The ensemble predictions, of shape (*batch_shape, dim_ensemble).\n        y: The ground truth observations, of shape (*batch_shape).\n        biased: If True, uses the biased estimator for E[|X - X'|]. If False, uses the unbiased estimator.\n            The unbiased estimator divides by m * (m - 1) instead of m\u00b2.\n\n    Returns:\n        The calculated CRPS value for each forecast in the batch, of shape (*batch_shape).\n    \"\"\"\n    if x.shape[:-1] != y.shape:\n        raise ValueError(f\"The batch dimension(s) of x {x.shape[:-1]} and y {y.shape} must be equal!\")\n\n    # Get the number of ensemble members.\n    m = x.shape[-1]\n\n    # --- Accuracy term := E[|X - y|]\n\n    # Compute the mean absolute error across all ensemble members. Unsqueeze the observation for explicit broadcasting.\n    mae = torch.abs(x - y.unsqueeze(-1)).mean(dim=-1)\n\n    # --- Spread term B := 0.5 * E[|X - X'|]\n    # This is half the mean absolute difference between all pairs of predictions.\n    # We use the efficient O(m log m) implementation with a summation over a single dimension.\n\n    # Sort the predictions along the ensemble member dimension.\n    x_sorted, _ = torch.sort(x, dim=-1)\n\n    # Calculate the coefficients (2i - m - 1) for the linear-time sum. These are the same for every item in the batch.\n    coeffs = 2 * torch.arange(1, m + 1, device=x.device, dtype=x.dtype) - m - 1\n\n    # Calculate the sum \u03a3\u1d62 (2i - m - 1)x\u1d62 for each forecast in the batch along the member dimension.\n    x_sum = torch.sum(coeffs * x_sorted, dim=-1)\n\n    # Calculate the full expectation E[|X - X'|] = 2 / m\u00b2 * \u03a3\u1d62 (2i - m - 1)x\u1d62.\n    denom = m * (m - 1) if not biased else m**2\n    half_mean_spread = 1 / denom * x_sum  # 2 in numerator here cancels with 0.5 in the next step\n\n    # --- Assemble the final CRPS value.\n    crps_value = mae - half_mean_spread  # 0.5 already accounted for above\n\n    return crps_value\n</code></pre>"},{"location":"reference/#torch_crps.ensemble_crps.crps_ensemble_naive","title":"<code>crps_ensemble_naive(x, y, biased=True)</code>","text":"<p>Computes the Continuous Ranked Probability Score (CRPS) for an ensemble forecast.</p> <p>This implementation uses the equality</p> \\[ CRPS(X, y) = E[|X - y|] - 0.5 E[|X - X'|] \\] <p>It is designed to be fully vectorized and handle any number of leading batch dimensions in the input tensors, as long as they are equal for <code>x</code> and <code>y</code>.</p> <p>See Also</p> <p>Zamo &amp; Naveau; \"Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts\"; 2017</p> <p>Note</p> <ul> <li>This implementation uses an inefficient algorithm to compute the term E[|X - X'|] in O(m\u00b2) where m is the number of ensemble members. This is done for clarity and educational purposes.</li> <li>This implementation exactly matches the energy formula, see (NRG) and (eNRG), in Zamo &amp; Naveau (2017).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The ensemble predictions, of shape (*batch_shape, dim_ensemble).</p> required <code>y</code> <code>Tensor</code> <p>The ground truth observations, of shape (*batch_shape).</p> required <code>biased</code> <code>bool</code> <p>If True, uses the biased estimator for E[|X - X'|]. If False, uses the unbiased estimator. The unbiased estimator divides by m * (m - 1) instead of m\u00b2.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The calculated CRPS value for each forecast in the batch, of shape (*batch_shape).</p> Source code in <code>torch_crps/ensemble_crps.py</code> <pre><code>def crps_ensemble_naive(x: torch.Tensor, y: torch.Tensor, biased: bool = True) -&gt; torch.Tensor:\n    \"\"\"Computes the Continuous Ranked Probability Score (CRPS) for an ensemble forecast.\n\n    This implementation uses the equality\n\n    $$ CRPS(X, y) = E[|X - y|] - 0.5 E[|X - X'|] $$\n\n    It is designed to be fully vectorized and handle any number of leading batch dimensions in the input tensors,\n    as long as they are equal for `x` and `y`.\n\n    See Also:\n        Zamo &amp; Naveau; \"Estimation of the Continuous Ranked Probability Score with Limited Information and Applications\n        to Ensemble Weather Forecasts\"; 2017\n\n    Note:\n        - This implementation uses an inefficient algorithm to compute the term E[|X - X'|] in O(m\u00b2) where m is\n        the number of ensemble members. This is done for clarity and educational purposes.\n        - This implementation exactly matches the energy formula, see (NRG) and (eNRG), in Zamo &amp; Naveau (2017).\n\n    Args:\n        x: The ensemble predictions, of shape (*batch_shape, dim_ensemble).\n        y: The ground truth observations, of shape (*batch_shape).\n        biased: If True, uses the biased estimator for E[|X - X'|]. If False, uses the unbiased estimator.\n            The unbiased estimator divides by m * (m - 1) instead of m\u00b2.\n\n    Returns:\n        The calculated CRPS value for each forecast in the batch, of shape (*batch_shape).\n    \"\"\"\n    if x.shape[:-1] != y.shape:\n        raise ValueError(f\"The batch dimension(s) of x {x.shape[:-1]} and y {y.shape} must be equal!\")\n\n    # --- Accuracy term := E[|X - y|]\n\n    # Compute the mean absolute error across all ensemble members. Unsqueeze the observation for explicit broadcasting.\n    mae = torch.abs(x - y.unsqueeze(-1)).mean(dim=-1)\n\n    # --- Spread term := 0.5 * E[|X - X'|]\n    # This is half the mean absolute difference between all pairs of predictions.\n\n    # Create a matrix of all pairwise differences between ensemble members using broadcasting.\n    x_i = x.unsqueeze(-1)  # shape: (*batch_shape, m, 1)\n    x_j = x.unsqueeze(-2)  # shape: (*batch_shape, 1, m)\n    pairwise_diffs = x_i - x_j  # shape: (*batch_shape, m, m)\n\n    # Take the absolute value of every element in the matrix.\n    abs_pairwise_diffs = torch.abs(pairwise_diffs)\n\n    # Calculate the mean of the m x m matrix for each batch item, i.e, not the batch shapes.\n    if biased:\n        # For the biased estimator, we use the mean which divides by m\u00b2.\n        mean_spread = abs_pairwise_diffs.mean(dim=(-2, -1))\n    else:\n        # For the unbiased estimator, we need to exclude the diagonal (where i=j) and divide by m(m-1).\n        m = x.shape[-1]  # number of ensemble members\n        mean_spread = abs_pairwise_diffs.sum(dim=(-2, -1)) / (m * (m - 1))\n\n    # --- Assemble the final CRPS value.\n    crps_value = mae - 0.5 * mean_spread\n\n    return crps_value\n</code></pre>"},{"location":"development/getting_started/","title":"Getting Started","text":""},{"location":"development/getting_started/#getting-started-for-developers","title":"Getting Started for Developers","text":""},{"location":"development/getting_started/#project-structure","title":"Project Structure","text":"File / Directory Purpose <code>.github</code> CI/CD workflow definitions and a PR template <code>torch_crps</code> Project import modules <code>docs</code> Documentation directory (better write docs there instead of <code>readme.md</code>) <code>tests</code> Python module unit- &amp; integration tests <code>.pre-commit-config.yaml</code> <code>git</code> hook definitions comsumed by <code>pre-commit</code> <code>license.md</code> The license in its long form <code>mkdocs.yml</code> Documentation config consumed by <code>mkdocs</code> <code>pyproject.toml</code> Project information, dependencies and task runner configurations <code>readme.md</code> General project overview, displayed when visiting GitHub repository <code>uv.lock</code> Contains the locked dependencies to exactly reproduce installations."},{"location":"development/getting_started/#dependency-management-packaging","title":"Dependency Management &amp; Packaging","text":"<p>To keep the dependencies of different projects from interfering with each other, it is highly recommended to create an isolated python environment for every project. We use <code>uv</code> to address this issue. By running <code>uv sync</code> inside the project directory, a new virtual environment is created automatically into which all your dependencies are installed (from the <code>uv.lock</code> file). This is different from running <code>pip install .</code> in an isolated virtual environment as this might use different dependency versions. Afterwards you can run any command within the virtual environment by simply calling</p> <pre><code>uv run &lt;command&gt;\n</code></pre>"},{"location":"development/getting_started/#testing","title":"Testing","text":"<p>Executing</p> <pre><code>uv run pytest --cov\n</code></pre> <p>will run pytest, compute the test coverage and fail if below the minimum coverage defined by the <code>tool.coverage.report.fail_under</code> threshold in the <code>pyproject.toml</code> file.</p>"},{"location":"development/getting_started/#documentation","title":"Documentation","text":"<p>The code documentation is based on <code>mkdocs</code> which converts markdown files into a nicely-rendered web-page. In particular, we use the <code>mkdocs-material</code> package which offers more than just theming. To generate documentation for different versions, <code>mike</code> is used as a plugin within <code>mkdocs</code>.</p> <p>To build and develop docs on a local server, run</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>To deploy the docs to the <code>gh-pages</code> remote branch, call</p> <pre><code>uv run mike deploy --push --update-aliases &lt;version&gt; &lt;alias&gt;\n</code></pre> <p>where <code>&lt;alias&gt;</code> may be any name alias for your version such as <code>latest</code>, <code>stable</code> or <code>whatever</code>.</p> <p>The final documentation is located at:</p> <pre><code>https://famura.github.io/torch-crps/&lt;alias&gt;\n</code></pre>"},{"location":"development/getting_started/#git-hooks","title":"Git Hooks","text":"<p>We use <code>pre-commit</code> to run git hooks helping you to develop high-quality code. The hooks are configured in the <code>.pre-commit-config.yaml</code> file and executed before commit.</p> <p>For instance, <code>ruff</code> &amp; <code>ruff-format</code> fix the code base in-place to adhere to reasonable coding standards. <code>mypy</code>mypy &amp; <code>ruff</code> lint the code for correctness. These tools are configured via <code>pyproject.toml</code> and <code>.pre-commit-config.yaml</code> files.</p> <p>Installation</p> <p>After you cloned this project and plan to develop in it, don't forget to install these hooks via</p> <pre><code>uv run pre-commit install\n</code></pre> Available pre-commit hooks <pre><code>minimum_pre_commit_version: \"3.6.0\"\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v6.0.0\n    hooks:\n      # - id: check-added-large-files\n      - id: check-ast\n      - id: check-case-conflict\n      - id: check-merge-conflict\n      - id: check-shebang-scripts-are-executable\n      - id: check-symlinks\n      - id: check-toml\n      - id: check-yaml\n        args: [\"--unsafe\"]\n      - id: end-of-file-fixer\n      # - id: no-commit-to-branch # default: main, master\n      - id: trailing-whitespace\n\n  - repo: https://github.com/python-jsonschema/check-jsonschema\n    rev: 0.33.3\n    hooks:\n      - id: check-dependabot\n      - id: check-github-actions\n      - id: check-github-workflows\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.13.0\n    hooks:\n      - id: ruff-format\n      - id: ruff\n        args: [\"--unsafe-fixes\"]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.18.1\n    hooks:\n      - id: mypy\n        args: [\"--explicit-package-bases\"]\n</code></pre>"},{"location":"development/getting_started/#github-actions","title":"GitHub Actions","text":"<p>There are basic CI and CD pipelines, executed as GitHub Actions workflow when pushing changes or opening PR's.</p> Available workflows .github/workflows/ci.yaml.github/workflows/cd.yaml <pre><code>name: Continuous Integration\n\non:\n    pull_request:\n        types: [opened, ready_for_review, reopened, synchronize]\n    workflow_call:\n    workflow_dispatch:\n\nconcurrency:\n    group: ${{ github.job }}/${{ github.workflow }}/${{ github.head_ref || github.ref }}\n    cancel-in-progress: true\n\njobs:\n    ci-default-python-version:\n        name: Default Python Version\n        runs-on: ubuntu-latest\n        permissions:\n            contents: write\n            pull-requests: write\n        timeout-minutes: 120\n\n        steps:\n            - name: Check out repository\n              uses: actions/checkout@v6\n\n            - name: Set up uv\n              uses: astral-sh/setup-uv@v7\n\n            - name: Lint &amp; test\n              uses: ./.github/actions/lint-test\n\n            - name: Add coverage comment\n              if: github.event_name == 'pull_request'\n              uses: MishaKav/pytest-coverage-comment@v1\n              with:\n                  coverage-path-prefix: \"torch_crps/\"\n                  junitxml-path: pytest.xml\n                  pytest-xml-coverage-path: coverage.xml\n\n            - name: Build &amp; deploy temporary docs\n              if: github.event_name == 'pull_request' &amp;&amp; github.event.pull_request.draft == false\n              uses: ./.github/actions/publish-docs\n              with:\n                  alias: pr-${{ github.event.number }}\n                  version: next-pr-${{ github.event.number }}\n\n            - name: Add docs comment\n              if: github.event_name == 'pull_request' &amp;&amp; github.event.pull_request.draft == false\n              uses: marocchino/sticky-pull-request-comment@v2.9.4\n              with:\n                  header: docs-comment\n                  message: |\n                      :books: Created [temporary docs](https://famura.github.io/torch-crps/pr-${{ github.event.number }}).\n\n                      Useful URLs:\n\n                      - [Coverage](https://famura.github.io/torch-crps/pr-${{ github.event.number }}/exported/coverage)\n                      - [Tests](https://famura.github.io/torch-crps/pr-${{ github.event.number }}/exported/tests)\n\n    ci-other-python-versions:\n        if: github.event.pull_request.draft == false\n        name: Other Python Versions\n        runs-on: ubuntu-latest\n        strategy:\n            matrix:\n                python-version: [3.13]\n        timeout-minutes: 120\n\n        steps:\n            - name: Check out repository\n              uses: actions/checkout@v6\n\n            - name: Set up uv\n              uses: astral-sh/setup-uv@v7\n\n            - name: Set Python version to ${{ matrix.python-version }}\n              run: uv python pin ${{ matrix.python-version }}\n\n            - name: Lint &amp; test\n              uses: ./.github/actions/lint-test\n</code></pre> <pre><code>name: Continuous Deployment\n\non:\n    push:\n        branches: [main]\n    workflow_dispatch:\n        inputs:\n            bumped-version-part:\n                description: \"The version part to bump.\"\n                type: choice\n                options:\n                    - major\n                    - minor\n                    - patch\n                default: patch\n                required: true\n\nconcurrency:\n    group: ${{ github.workflow }}/${{ github.head_ref || github.ref }}\n    cancel-in-progress: true\n\njobs:\n    bump-version:\n        name: Bump Version\n        runs-on: ubuntu-latest\n        container: docker:git\n        permissions:\n            contents: write\n        timeout-minutes: 10\n        steps:\n            - name: Install prerequisites\n              run: apk add nodejs\n\n            - name: Check out repository\n              uses: actions/checkout@v6\n\n            - name: Bump version and push tag\n              id: version\n              uses: mathieudutour/github-tag-action@v6.2\n              with:\n                  default_bump: ${{ github.event.inputs.bumped-version-part || 'patch' }}\n                  github_token: ${{ secrets.GITHUB_TOKEN }}\n\n            - name: Add version info\n              run: echo \"Bumped ${VERSION_PART} version part from ${OLD_TAG} to ${NEW_TAG}.\" &gt;&gt; $GITHUB_STEP_SUMMARY\n              env:\n                  VERSION_PART: ${{ steps.version.outputs.release_type }}\n                  OLD_TAG: ${{ steps.version.outputs.previous_tag }}\n                  NEW_TAG: ${{ steps.version.outputs.new_tag }}\n\n    ci:\n        name: CI\n        needs: bump-version\n        uses: ./.github/workflows/ci.yaml\n        secrets: inherit\n        permissions:\n            contents: write\n            pull-requests: write\n\n    deploy:\n        name: Deploy Docs\n        needs: ci\n        if: github.repository == 'famura/torch-crps'\n        runs-on: ubuntu-latest\n        timeout-minutes: 30\n        permissions:\n            contents: write\n        steps:\n            - name: Check out repository\n              uses: actions/checkout@v6\n              with:\n                  fetch-depth: 0\n\n            - name: Set up uv\n              uses: astral-sh/setup-uv@v7\n\n            - name: Lint &amp; test\n              uses: ./.github/actions/lint-test\n\n            - name: Build &amp; publish docs\n              uses: ./.github/actions/publish-docs\n\n    publish-pypi:\n        name: Publish to PyPI\n        needs: deploy\n        runs-on: ubuntu-latest\n        environment: release\n        timeout-minutes: 15\n        permissions:\n            id-token: write\n        steps:\n            - name: Check out repository\n              uses: actions/checkout@v6\n              with:\n                  fetch-depth: 0 # it is necessary for versioningit to get full git history\n\n            - name: Set up uv\n              uses: astral-sh/setup-uv@v7\n\n            - name: Build package\n              run: uv build\n\n            - name: Publish to PyPI\n              uses: pypa/gh-action-pypi-publish@release/v1\n</code></pre>"},{"location":"development/installation/","title":"Installation","text":""},{"location":"development/installation/#installation-for-developers","title":"Installation for Developers","text":""},{"location":"development/installation/#cloning-the-repository","title":"Cloning the Repository","text":"<p>For development, you need the source code. Clone the repository by executing</p> <pre><code>git clone https://github.com/famura/torch-crps.git\n</code></pre>"},{"location":"development/installation/#uv","title":"uv","text":"<p>This project is managed by <code>uv</code>, an extremely fast Python package and project manager, written in Rust. This means, however, that <code>uv</code> needs to be installed before you can run the CLI or install the development version. The official <code>uv</code> installation docs show several ways to install []<code>uv</code>]uv on different platforms and under different conditions.</p> Installation for the lazy ones <p>This is just a quick tip on installing uv, better see the official uv docs</p> via curl on macOS &amp; Linux (recommended)via conda (not recommended) <p>Run</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <pre><code>conda activate &lt;some-environment&gt;\nconda install pip\npip install pipx\npipx install uv\nconda deactivate\n</code></pre>"},{"location":"development/installation/#managing-python","title":"Managing Python","text":"<p>With <code>uv</code>, you can install a suitable python version by running</p> <pre><code>uv python install\n</code></pre> <p>to install the latest stable Python version. See the uv docs for more details.</p>"},{"location":"development/installation/#actual-installation","title":"Actual Installation","text":"<p>The final project installation should be easy. Run this from the projects root level:</p> <pre><code>uv sync\n</code></pre> <p>No project development intended?</p> <p>If you don't need any development setup, you can add the <code>--no-dev</code> flag to skip development dependencies.</p> Computer says no\u2026 <p>In some cases, this does not work right away. Please create and issue such that we can collect failure cases and hints to their solution here.</p> What? Hint placeholder issue placeholder hint"}]}